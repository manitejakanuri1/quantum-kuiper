/**
 * Test crawl with sitesbysara.com to verify storage fix
 */

require('dotenv').config({ path: '../.env.local' });
const { createClient } = require('@supabase/supabase-js');
const { v4: uuidv4 } = require('uuid');
const fetch = require('node-fetch');

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;
const supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY;
const supabase = createClient(supabaseUrl, supabaseKey);

async function testCrawl() {
    console.log('üß™ Testing Website Crawl: sitesbysara.com\n');
    console.log('='.repeat(80));

    const testWebsite = {
        name: "Sites by Sara Agent",
        url: "https://sitesbysara.com/"
    };

    const agentId = uuidv4();
    const userId = '26128add-c536-4a92-a655-f790b9841ac3';

    console.log(`\nüìù Creating test agent...`);
    console.log(`   Name: ${testWebsite.name}`);
    console.log(`   Website: ${testWebsite.url}`);
    console.log(`   Agent ID: ${agentId}`);

    // Create agent
    const { data: agent, error: agentError } = await supabase
        .from('agents')
        .insert({
            id: agentId,
            user_id: userId,
            name: testWebsite.name,
            website_url: testWebsite.url,
            face_id: 'cace3ef7-a4c4-425d-a8cf-a5358eb0c427',
            voice_id: '1b160c4cf02e4855a09efd59475b9370',
            status: 'active',
            crawl_status: 'pending'
        })
        .select()
        .single();

    if (agentError) {
        console.error(`‚ùå Error creating agent:`, agentError);
        process.exit(1);
    }

    console.log(`‚úÖ Agent created successfully\n`);

    // Crawl website
    console.log(`üï∑Ô∏è  Crawling website: ${testWebsite.url}`);
    console.log(`   This may take 1-2 minutes...\n`);

    try {
        const crawlResponse = await fetch('http://localhost:8080/api/crawl-website', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                agentId: agent.id,
                websiteUrl: testWebsite.url
            })
        });

        if (!crawlResponse.ok) {
            const error = await crawlResponse.json();
            console.error(`‚ùå Crawl failed with status ${crawlResponse.status}:`);
            console.error(JSON.stringify(error, null, 2));
            process.exit(1);
        }

        const crawlData = await crawlResponse.json();
        console.log(`‚úÖ Crawl successful!`);
        console.log(`   Pages crawled: ${crawlData.pagesCount}`);
        console.log(`   Chunks stored: ${crawlData.chunksStored}\n`);

        // Verify chunks in database
        console.log(`üîç Verifying chunks in database...`);

        const { data: kb } = await supabase
            .from('knowledge_bases')
            .select('id, status')
            .eq('agent_id', agent.id)
            .eq('source_url', testWebsite.url)
            .single();

        if (!kb) {
            console.error(`‚ùå No knowledge base found for agent`);
            process.exit(1);
        }

        console.log(`   Knowledge base ID: ${kb.id}`);
        console.log(`   Status: ${kb.status}`);

        const { data: chunks, error: chunksError } = await supabase
            .from('document_chunks')
            .select('id, embedding, content')
            .eq('kb_id', kb.id);

        if (chunksError) {
            console.error(`‚ùå Error fetching chunks:`, chunksError);
            process.exit(1);
        }

        console.log(`   Total chunks in DB: ${chunks.length}`);
        console.log(`   Chunks with embeddings: ${chunks.filter(c => c.embedding).length}\n`);

        // Show sample content
        if (chunks.length > 0) {
            console.log(`üìÑ Sample chunk content:`);
            console.log(`   "${chunks[0].content.substring(0, 150)}..."\n`);
        }

        // Summary
        console.log('='.repeat(80));
        console.log('üìä Test Results Summary');
        console.log('='.repeat(80));

        const success = crawlData.chunksStored > 0 && chunks.length === crawlData.chunksStored;

        if (success) {
            console.log('‚úÖ SUCCESS: Storage fix is working with sitesbysara.com!');
            console.log(`   - Pages crawled: ${crawlData.pagesCount}`);
            console.log(`   - Chunks stored: ${crawlData.chunksStored}`);
            console.log(`   - Chunks in DB: ${chunks.length}`);
            console.log(`   - All chunks have embeddings: ${chunks.every(c => c.embedding) ? 'Yes' : 'No'}`);
            console.log(`\nüéâ Knowledge base created successfully for this agent!`);
        } else {
            console.log('‚ö†Ô∏è  ISSUE DETECTED:');
            console.log(`   - API reported: ${crawlData.chunksStored} chunks`);
            console.log(`   - Database contains: ${chunks.length} chunks`);
        }

        console.log('\n' + '='.repeat(80));
        console.log(`\nüí° Agent Details:`);
        console.log(`   Agent ID: ${agentId}`);
        console.log(`   Website: ${testWebsite.url}`);
        console.log(`   Knowledge Base ID: ${kb.id}`);
        console.log(`\nüí¨ Test this agent with a question:`);
        console.log(`   "What services does Sara offer?"`);
        console.log(`   "Tell me about yourself"`);

    } catch (error) {
        console.error('‚ùå Crawl error:', error);
        console.error('Stack trace:', error.stack);
        process.exit(1);
    }
}

testCrawl().catch(console.error);
